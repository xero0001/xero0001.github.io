---
title: Statistics 110 - 07 Joint Distribution
date: 2019-05-24 10:07:00
categories:
- statistics
tags:
---

# Joint Distribution

## 확률변수 X,Y의 joint CDf

$$F(x,y) = P(X \le x, Y \le y)$$

## 확률변수 X,Y의 joint PDf

$$f(x,y)=\frac{\partial}{\partial x \partial y}F(x,y)$$

$$f(x,y) \text{ s.t. } P((x,y) \in A)= \int \int_A f(x,y)dxdy$$

---

# Marginal Distribution

다른 확률변수의 값을 무시한 부분집합속의 확률변수를 의미한다.

## 확률변수 X의 marginal CDF

$$f(x)=P(X \le x)$$

## 확률변수 X의 marginal PDF

$$f(x)=\int_{-\infty}^{\infty}f(x,y)dy$$

## 결합 분포에서 주변 분포 구하기

이산) $$P(X=x)=\sum_y P(X=x,Y=y)$$

연속) $$f_X(y)=\int_{-\infty}^{\infty} f_{X,Y}(x,y)dy$$

---

# Conditional Distribution

## 조건부 분포 Y|X 의 PDF

$$f_{Y|X}(y|x)=\frac{f_{X,Y}(x,y)}{f_X(x)}=\frac{f_{X|Y}f_Y(y)}{f_X(x)}$$

---

# 독립

확률변수 X,Y가 독립일 때, $$F(x,y)=F_X (x) F_Y(y)$$ 가 성립한다.

이산) $$P(X=x,Y=y)=P(X=x)P(Y=y)$$

연속) $$f(x,y)=f_X(x)f_Y(y)$$ for all $$(x,y) \in R$$

## Example

X,Y가 독립이면 P(X=0)P(Y=0)=P(X=0,Y=0)

X,Y가 독립이 아니면 P(X=0)P(Y=0)!=P(X=0,Y=0)

### 독립인 경우

![71](/assets/figures/ST/7-1.png)

사각형 내에서 균등분포를 따르는 X,Y

### 종속인 경우

![72](/assets/figures/ST/7-2.png)

원 내에서 균등 분포를 따르는 X,Y

---

# 2차원 LOTUS

X,Y가 joint PDF f(x,y)를 가지고 g(x,y)가 x,y에 대한 함수일 때,

$$E(g(x,y))=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x,y)f(x,y)dxdy$$

가 성립한다.

## 정리

X,Y가 독립일 때, E(XY)=E(X)E(Y)가 성립한다.

## 두 표준정규분포 확률변수 사이 거리의 기댓값

![76](/assets/figures/ST/7-6.png)

---

# Multinomial Distribution

$$Mult(n, \vec{p})$$

Binomial의 일반화이다.

## 정의

$$X \sim Mult(n, \vec{p})$$

$$\vec{X}=(X_1,...,X_n)$$ n개 object들을 k개의 카테고리에 독립적으로 할당하는 것.

$$X_j=$$j번째 카테고리에 할당된 object의 수

$$\vec{p}=(p_1,...,p_k) (p_j \ge 0, \sum_j p_j=1)$$

$$p_j=$$j번째 카테고리에 할당될 확률

## joint PMF

$$P(X_1=n_1,...,X_k=n_k)=\frac{n!}{n_1!...n_k!}\cdot p_1^{n_1} \cdots p_k^{n_k}$$

단, $$\sum_{j} n_j=n$$

## 주변분포

$$\vec{X} \sim Mult_k(n,\vec{p})$$

일 때, $$X_j$$의 주변분포는?

$$X_j \sim Bin(n,p_j)$$

$$E(X_j)=np_j, Var(X_j)=np_j(1-p_j)$$

## Lumping Property(덩어리 성질)

$$\vec{X}=(x_1,...,x_{10}) \sim Mult(n,(p_1,...,p_{10}))$$

이라고 한다.

만약 10개의 정당이 있지만 두개의 정당만 크고 나머지는 점유율이 작다고 할때, 나머지 정당들을 묶는 것이 가능하다.

$$\vec{Y}=(X_1,X_2,X_3+...+X_{10}) \sim Mult(n, (p_1,p_2,p_3+...+p_{10}))$$

을 만족한다.

## 조건부 분포

$$\vec{X} \sim Mult(n,\vec{p})$$

$$X_1=n_1$$ 이고, $$(X_2,...,X_k) \sim Mult(n-n_1,(p'_2 \cdots, p'_k)$$

라고 할 때,

$$p'_2=P$$(카테고리 2에 속함 \| 카테고리 1에 속하지 않음)

$$=\frac{p_2}{1-p_1} = \frac{p_2}{p_2+...+p_k}$$

$$p'_j = \frac{p_j}{p_2+...+p_k}$$

---

# Cauchy Distribution

두 표준정규분포의 비율! 다양한 분야에 응용된다.

![7-5](/assets/figures/ST/7-5.PNG)

이는 악랄한 정의를 갖고있는데, 기댓값을 구하려고 하면 발산해서 구할 수가 없다. 그런데 분산은 있다.

---

# Covariance

분산은 기대값과 달리 선형성이 없다.

물론 합의 분산이 쓸모없는 것은 아니지만 다른 방법을 찾는 것이 좋다.

공분산은 합의분산을 다루기 위해 필요하기도 하고, 하나의 확률변수만이 아닌 두개의 확률변수를 같이 분석하기 위해 필요하다.

## 정의

X, Y는 같은 표본공간의 두 확률변수이다.

$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$$

$$=E(XY)-E(X)E(Y)$$

둘이 함께 어떻게 변화하는지를 살펴보기 위한 것이다.

## 특성과 정리

![7-3](/assets/figures/ST/7-3.PNG)

7번은 합의 분산으로 중요하다.

독립일 때 (Cov=0) 합의 분산은 분산의 합과 같다는 것을 알 수 있다.

---

# Correlation

Theorem은 코시-슈바르츠 부등식.

![7-4](/assets/figures/ST/7-4.PNG)

각각의 분산은 0보다 크기 때문에 $$-1 \ge \rho \ge 1$$
