---
title: Statistics 110 - 04 Expectation
date: 2019-05-24 10:04:00
categories:
- statistics
tags:
---

# Expectation

확률변수의 평균값이다.

그러나 동일하게 취급할지, 각각 서로 다르게 weight할지가 다르다.

## Unweighted average

$$1,2,3,4,5,6 \rightarrow \frac{1+2+3+4+5+6}{6}$$

## Weighted average

$$1,1,1,1,1,3,3,5 \rightarrow \frac{5}{8} \times 1 + \frac{2}{8} \times 3 + \frac{1}{8} \times 5$$  
각 가중치를 전부 더하면 1이 된다.

여기서 가중치는 확률이 된다.

---

# Expectation of R.V

## 이산확률변수(discrete r.v)의 기댓값

$$E(X) = \sum_x XP(X=x),(P(X=x)>0)$$  
$$\rightarrow \sum 값 * 확률질량함수$$

## 베르누이 확률변수(Bernoulli r.v)의 기댓값

$$X \sim Bern(p)$$  
$$E(X)=1 \cdot P(X=1) + 0 \cdot P(X=0)=p$$

X=사건 A가 발생한 경우 1, 그 외의 경우 0  
$$E(X)=P(A) \rightarrow$$ X를 지시확률변수로 생각해 볼 수 있다.

## 이항 확률변수(Binomial r.v)의 기대값

$$X \sim Bin(n,p)$$  
$$E(X)=\sum_{k=1}^{n}k \binom{n}{k} p^k q^{n-k}=\sum_{k=1}{n} n \binom{n-1}{k-1} p^k q^{n-k}$$  
$$=np \sum_{k=1}^n \binom{n-1}{k-1} p^{k-1}q^{n-k}$$

j=k-1이라고 하면,  
$$=np \sum_{k=1}^n \binom{n-1}{j} p^{j}q^{n-1-j}$$

이항정리에 의해 $$\sum_{k=1}^{n} \binom{n-1}{j} p^j q^{n-1-j}=1$$  
$$=np$$

---

# 기대값의 선형성(linearity)

1. $$E(X+Y)=E(X)+E(Y) \rightarrow X,Y$$가 서로 독립이 아닌 경우에도 성립!
2. $$E(cX)=cE(X)$$, c는 상수

독립이 아니어도 성립하기 때문에 굉장히 유용하다.

## 선형성 증명

이산확률변수에 대해서.

$$\text{Let }T=X+Y$$

$$\text{Show }E(T)=E(X)+E(Y)$$

$$
\rightarrow \sum_t t P(T=t) =^? \sum_x x P(X=x) + \sum_y y P(Y=y)
$$

위는 각각의 확률에 따라 weighted한 평균이다. t는 T의 possible value, x는 X의.. 그런식이다.

이것을 증명하기 위해선 두가지 방법이 있는데, 우측을 풀어 좌측과 같다는걸 보여주는거고, 좌측을 풀어 우측과 같다는것을 보여주는것이다.

조약돌 세계를 다시 생각해보자.

![Linear](/assets/figures/10-1.png)

여기서 X의 possible value는 0,1,2,3으로 되어있지만 실제로는 어떤 값을 가져도 상관없다.

각각의 조약돌을 s라고 한다면,

$$E(X)=\sum_x xP(X=x)=\sum_x X(s)P(\{s\})$$

두번째 식처럼 random variable에 대한 합을 구하는 것이 아니라,  
각 조약돌에 대한 합을 구하는 것이다.  
$$P(\{s\})$$는 조약돌의 질량을 의미한다.

둘의 차이는 random variable은 grouped되었다는 것이고,  
조약돌은 ungrouped라는 것이다.  
둘다 똑같은 weighted 평균이다.

### Proof (discrete case)

$$
E(T)=\sum_s(X+Y)(S)P(\{s\})=\sum_s(X(s)+Y(s))P(\{s\}) \\\\
=\sum_s X(s)P(\{s\}) + \sum_s Y(s)P(\{s\}) \\\\
=E(X)+E(Y)
$$

그래서 다음 식도 가능하다.

$$E(cX)=cE(X)$$, c는 상수  
이 식은 X=Y라는 가장 극단적인 종속 상황에서도 성립한다.

$$E(X+Y)=E(2X)=2E(X)=E(X)+E(Y)$$

## 이항확률변수의 기댓값(선형성 이용)

$$X=X_1+...+X_n$$이기 때문에($$X_i$$는 각각 베르누이 시행)
$$E(X)=n \cdot E(X_1)=np$$

---

# 기하확률변수(geometric random variable)

Geom(p): 여러 번의 Bern(p) 독립시행에서 첫 번째 성공까지의 실패 수  
$$X \sim Geom(p),(q=1-p)$$라고 할 때,

X의 PMF:  
$$P(X=k)=q^kp,(k \in \{0,1,...\})$$

조건확인:
$$\sum_{k=1}{\inf}pq^k = \frac{p}{1-q}=1$$

## 기하확률변수의 기댓값

$$E(X)=\sum_{k=0}^{\inf}k p q^k = p \sum_{k=0}^{\inf}k q^k$$

$$\sum_{k=0}^{\infty} q^k = \frac{1}{1-q}$$

이를 미분하면

$$\sum_{k=1}^{\infty} k q^{k-1}= \frac{1}{(1-q)^2}$$

$$\rightarrow \sum_{k=1}^{\infty} k q^k = \frac{q}{p^2}$$

$$\therefore E(X) = p \sum_{k=0}^{\infty} k q^k = p \cdot \frac{q}{p^2} = \frac{q}{p}$$

## Story proof 2강 이용하여 해석

$$c=E(X)$$

$$c= 0 \cdot p + (1+c) \cdot q$$

$$=q + cq$$

$$c=\frac{q}{1-q}=\frac{q}{p}$$

## 첫번째 성공(First Success) 분포

$$X \sim FS(p)$$

$$Y=X-1$$이라 하였을 때, $$Y \sim Geom(p)$$

$$
E(X)=E(Y)+1 \\\\
=\frac{q}{p}+1 = \frac{1}{p}
$$

---

# 음이항분포(Negative Binomial)

$$NegBin(r,p)$$

모수는 r,p이다.

## 의미

여러 번의 Bern(p) 독립시행 중에서 r번째 성공까지의 실패 횟수.

## PMF

$$P(X=n)=\binom{n+r-1}{r-1}p^r q^n, n=0,1,2,...$$

## 지시확률변수

Most simple case: r=1일 때, $$X \sim Geom(p)$$

$$E(X)=\frac{q}{p}$$

$$E(X)=E(X_1+X_2+...+X_r)=E(X_1)+...+E(X_r)$$

$$X_j$$는 j-1번째와 j번째 성공 사이의 실패 횟수라고 할 때,

$$X_j \sim Geom(p)$$ 이므로

$$E(X)=r \times \frac{q}{p}$$
