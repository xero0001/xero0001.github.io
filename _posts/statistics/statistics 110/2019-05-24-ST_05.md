---
title: Statistics 110 - 05 Continuous Random Variable
date: 2019-05-24 10:05:00
categories:
- statistics
tags:
---

# Discrete vs Continuous, the Uniform

![5-1](/assets/figures/ST/5-1.png)

CDF를 미분하면 PDF가 된다.

기대값도 이산합이 아니라 적분으로 계산한다.

균등분포는 이산에서 조약돌 세계의 모든 조약돌이 같은 무게인 것과 비슷하다.

연속에서 구간내 모든 지점의 밀도가 동일한 것.

![5-3](/assets/figures/ST/5-3.png)

![5-4](/assets/figures/ST/5-4.png)

![5-5](/assets/figures/ST/5-5.png)

## Universality of Uniform Distribution

모의실험시 유용하게 사용.

![5-2](/assets/figures/ST/5-2.png)

---

# Independence of random variable

이산에서는

$$P(X_1 = x_1,...,X_n=x_n)=P(X_1=x_1) \cdot ... \cdot P(X_n = x_n)$$

Joint PMF를 사용했지만,

연속에서는

$$P(X_1 \le x_1,...,X_n \le x_n)=P(X_1 \le x_1) \cdot ... \cdot P(X_n \le x_n)$$

for all $$x_1,...,x_n$$

이런 Joint CDF가 나타난다. CDF에서는 이것이 성립하면 확률변수가 독립적이라고 한다.

사건의 독립성보다 덜 복잡해 보인다. 사건의 독립성에서는 세 사건의 독립성을 보기위해 두개 끼리의 독립성(pairwise)과 세개 전부의 독립성(mutual)까지 다 보아야 했다.

그런데 자세히 보면 모든 $$x_1,...,x_n$$ 에 대해 성립해야 한다는 것이 중요하다.

증명은 별로 어렵지 않다고 한다.

이것의 의미는 이 여러 사건들 중 몇개가 일어나는 것을 안다고 해도 다른 사건의 실행 여부와 관계가 없다는 뜻이다.

그래서 pairwise보다 훨씬 강력하고 까다롭다.

이러한 완전한 독립성(Full independence)은 어떤 사건의 실행 여부를 알아도 나머지에 대해 아무것도 모르는 것이다.

---

# Poisson Distribution

$$X \sim Pois(\lambda )$$

## 의미

굉장히 여러번의 시행을 하지만, 성공의 확률이 매우 낮을 때의 성공 횟수 세기.

ex) 한 시간 동안 오는 이메일의 갯수.

## PMF

$$P(X=k)=\frac{e^{-\lambda}\lambda^k}{k!},(k \in {0,1,2,...})$$

$$\rightarrow \lambda$$는 속도를 나타내는 모수로, $$\lambda >0$$ 인 상수이다.

조건확인: $$\sum_{k=0}^{\infty} \frac{e^{-\lambda} \lambda^k}{k!}=e^{-lambda} e^{\lambda} = 1$$

## Poisson approximation

어떤 큰 숫자 n에 대하여 $$A_1,...,A_n$$의 사건들이 각각 $$P(A_j)=p_j$$라는 낮은 확률로 발생하고, 각 사건이 독립이거나 weekly dependent할 때,

발생하는 사건($$A_j$$)의 수는 $$Pois(\lambda)$$의 분포를 따른다.

$$\lambda=\sum p_j$$

또한 $$X \sim Bin(n,p)$$는 $$n \rightarrow \infty, p \rightarrow 0$$하고 $$np=\lambda$$ 가 상수로 유지될 때 (n과 p가 증가하는 속도가 같음)

이항확률변수 X의 분포는 포아송에 근사하게 된다.

### 증명

까지는 굳이 안해도 될듯..

$$n \rightarrow \infty$$ 할 때 몇몇 성분들이 1로 수렴하면서

$$\binom{n}{k} p^k (1-p)^{n-k} \approx \frac{\lambda^k}{k!}e^{-\lambda}$$

### 빗방울

길바닥에 빗방울이 떨어지는 횟수 또한 포아송 근사로 설명할 수 있다.

각 사각형에 빗방울이 떨어지는 사건은 이항분포이지만, 그 사건은 서로 독립이다.

빗방울은 많이 떨어지지만 한 사각형 안에 떨어질 확률은 작기 때문에, 포아송 분포로도 볼 수 있다.

---

# Normal Distribution

$$N(\mu, \sigma^2)$$

## Standard Normal Distribution

$$Z \sim N(0,1)$$

### PDF

$$f(z)=ce^{-z^2 /2}$$

$$\int_{-\infty}^{\infty} e^{-z^2/2}dz$$

Closed form이라 유도할 수 없다.

$$\int_{-\infty}^{\infty}e^{-z^2}/2 dz \int_{-\infty}^{\infty} e^{z^2}/2 dz $$

이렇게 제곱하면

$$
\int_{-\infty}^{\infty}e^{-x^2/2}dx\int_{-\infty}^{\infty} e^{-y^2/2}dy \\\\
=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} e^{-(x^2+y^2)/2}dxdy = \int_{2 \pi}^{0} \int_{0}^{\infty} e^{-r^2/2}r dr d \theta
$$

$$=\int_{0}^{2 \pi} \int_{0}^{\infty}e^{-u}dud \theta = 2 \pi$$

$$\therefore \int_{-\infty}^{\infty}e^{-z^2/2}dz = \sqrt{2 \pi}$$

$$c= \frac{1}{\sqrt{2 \pi}}$$

파이가 나타나는 것은 중간에 $$(x^2 + y^2)$$ 꼴이 지수에 나타나기 때문.

### 평균

$$Z \sim N(0,1)$$

$$E(Z)=0$$

기함수다.

### 분산

$$Var(Z)=E(Z^2)-\{E(Z)\}^2=E(Z^2)$$

$$=\frac{1}{\sqrt{2 \pi}}\int_{-\infty}^{\infty} z^2 e^{-z^2/2}dz = \frac{2}{\sqrt{2 \pi}}\int_{0}^{\infty} z^2 e^{-z^2/2}dz$$

$$u=z,dv=ze^{-z^2/2}$$

$$du=dz,v=-e^{-z^2/2}$$

$$=\frac{2}{\sqrt{2 \pi}} [uv]_0^{\infty} + \int_0^{\infty}e^{-z^2/2}dz=1$$

$$Var(Z)=E(Z^2)-{E(Z)}^2 = E(Z^2)=1$$

### CDF

$$\Phi (z)=\frac{1}{\sqrt{2 \pi}} \int _{-\infty}^{z} e^{-t^2 / 2} dt$$

이를 계산하기는 힘들다.

## 정규분포의 특성: 대칭

$$Z \sim N(0,1)$$ 이고 CDF $$\Phi$$ 를 가질 때,

$$E(Z)=0$$

$$E(Z^2)=Var(Z)=1$$

$$E(Z^3)=0$$

홀수차 적률은 기함수이기 때문.

정규분포의 대칭성으로 인해 $$-Z \sim N(0,1)$$

## 일반정규분포

$$X=\mu + \sigma Z$$ 일 때,

$$\mu \in R$$(평균, 위치(location) 만큼 이동)

$$\sigma >0$$(표준편차, 크기(scale) 만큼 스케일링)

$$E(X)= \mu$$

$$Var(X)= \sigma^2Var(Z)=\sigma^2$$

### 표준화

$$Z=\frac{X-\mu}{\sigma}$$

$$X \sim N(\mu, \sigma^2)$$

#### CDF

$$P(X \le x )=P(\frac{X-\mu}{\sigma} \lt \frac{x-\mu}{\sigma})$$

$$=\Phi(\frac{X-\mu}{\sigma})$$

#### PDF

$$\frac{1}{\sigma \sqrt{2 \pi}} e^{-(\frac{x-\mu}{\sigma})^2/2}$$

$$-X = -\mu +\sigma(-z) \sim N(-\mu, \sigma^2)$$

j=1,2,... 에 대하여 $$X_j \sim N(\mu_j, \sigma_j^2)$$ 이고 서로 독립일 때,

$$X_1+X_2 \sim N(\mu_1+\mu_2, \sigma_1^2 + \sigma_2^2)$$

$$X_1-X_2 \sim N(\mu_1-\mu_2, \sigma_1^2 + \sigma_2^2)$$

## 68-95-99.7% Rule

$$P(|X-\mu| \le \sigma) \approx 0.68$$

$$P(|X-\mu| \le 2\sigma) \approx 0.95$$

$$P(|X-\mu| \le 3\sigma) \approx 0.997$$

---

# LOTUS

$$E(g(x))=\sum_x g(x) P(X=x)$$

2X의 기댓값을 구할 때

$$\sum_x 2x P(X=x)$$

를 구하면 된다.

$$X^2$$의 기댓값을 구할 때

$$\sum_x x^2 P(X=x)$$

를 구하면 된다.

많은 사람들이 이것을 아무렇지 않게 사용하는데, 실제로는 까다로운 문제이다.

$$
\sum_x \sum_{S:X(s)=x} g(X(s))P({s}) =$$\sum_x \sum_{S:X(s)=x} P({s}) \\\\
=\sum_x g(x) P(X=x)
$$

이렇게 생각하면 이산에 대해서 증명할 수 있고, 아무 생각없이 사용해도 괜찮다는 것을 알 수 있다.  
이를 Law of the Unconscious Statistician 이라고 한다.

## 포아송 분포의 평균과 분산

LOTUS로 분산을 구해보자

### 평균

$$E(X)=\sum_{x=0}^{\infty} x \frac{\lambda^x e^{-\lambda}}{x!}=\lambda$$

### 분산

$$E(X^2)=\sum_{k=0}^{\infty} k^2 e^{-\lambda} \lambda^{k} / k!$$

아래 식을 미분하면,

$$\sum_{k=0}^{\infty} \frac{\lambda^k}{k!}=e^{\lambda}$$

다음이 나온다.

$$\lambda \sum_{k=1}^{\infty} \frac{k \lambda^{k-1}}{k!}=\sum_{k=1}^{\infty}\frac{k \lambda^k}{k!} = \lambda e^{\lambda}$$

이를 또 미분하면,

$$\sum_{k=0}^{\infty}\frac{k^2 \lambda^{k-1}}{k!}=\lambda e^{\lambda} + e^{\lambda} = e^{\lambda}(\lambda+1)$$

이를 대입하면.

$$=e^{-\lambda}e^{\lambda}(\lambda+1)\lambda$$

$$=\lambda^2+\lambda$$

$$
Var(X)=E(X^2)=\{E(X)\}^2 \\\\
=\lambda^2 + \lambda - \lambda^2 = \lambda
$$

## 이항분포의 분산

$$X=I_1 + ... + X_n, I_j \sim^{iid} Bern(p)$$

$$X^2=I_1^2 + ... + I_n^2 + 2I_1I_2+...2I_{n-1}I_n$$

$$E(X^2) = nE(I_1^2)+2\binom{n}{2} E(I_1I_2)$$

$$=np+n(n-1)p^2$$

$$=np+n^2p^2 - np^2$$

$$Var(X)=np(1-p)=npq$$

---

# Exponential Distribution

$$Expo(\lambda)$$

모수 $$\lambda$$

## PDF

$$f(x)= \lambda e^{-\lambda x}, x>0$$

조건확인: 적분시 1

## CDF

$$
F(x)= \int_0^x \lambda e^{-\lambda t}dt \\\\
=1-e^{-\lambda x}, x>0
$$

## 기댓값과 분산

$$Y=\lambda X$$일 때, $$Y \sim Expo(1)$$ 이다.

$$E(Y)=1$$

$$Var(Y)=1$$

일반적인 경우에는

$$X=\frac{Y}{\lambda}$$

$$E(X)=\frac{1}{\lambda}$$

$$Var(X)=\frac{1}{\lambda^2}$$

# 무기억성(memoryless property)

이산확률분포: 기하분포

연속확률분포: 지수분포

**이 둘은 각각의 분포에서 무기억성을 지닌 유일한 분포이다.**

무기억성 그자체가 기하분포와 지수함수이다.

## Conditional expectation

$$E(X|X>a)=a+\frac{1}{\lambda}$$
