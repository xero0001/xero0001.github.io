---
title: Math&Stat for Data Science - 02 Statistics for Data Science
date: 2019-04-29 12:10:00
categories:
- math, statistics
tags:
- [distribution, hypothesis, variable]
published: false
---

통계학은 크게 확률론과 회귀분석으로 구분된다. 밑바탕이 되는 지식이라고 할 수 있는 확률론에 대해서 수학자 라플라스는 “상식을 계산으로 바꾼 것에 불과하다”는 표현을 썼다. 물론 확률론이 수학적으로 도전적인 부분도 있지만, 밑바탕은 상식을 개념화한 것이라는 것을 상기시키는 인용구라고 생각한다.

*라플라스의 악마 (Laplace’s demon)

프랑스의 수학자 라플라스가 살았던 시절은 뉴튼과 라이프니치의 미분/적분이 세상에 알려져 행성 궤도의 움직임, 날씨와 해류에 따른 선박의 속도 변화 등등 이전 시대의 인류가 모델을 통한 계산 대신 관찰로만 설명했던 사실을 이론으로 정립, 설명하기 시작한 시대였다. 때문에 프랑스의 콧대 높은 수학자, 철학자들 상당수는 세상의 모든 원자의 움직임을 알 수 있다면 물체의 움직임, 나아가 인류의 의사 결정 모두를 추적할 수 있는, 말 그대로 결정론적인 사고방식에 사로잡혀 있었다.

확률론은 특정 사건이 일어날 “확률”을 따지는 학문이기 때문에, 그런 결정론적 사고방식에 대한 반박에서 나온 지적 흐름의 일환이라고 할 수 있고, 라플라스 같은 수학적 결정론자들과 항상 학문적인 (or 철학적인) 논쟁을 할 수 밖에 없었다. 위의 인용구는 그런 일련의 사상사적 흐름에서 당시의 수학자들이 통계학을 어떤 시선으로 바라봤는지를 단적으로 보여주는 예시라고 할 수 있겠다.

# Distribution Function
## 분포함수 - 정규분포, Log정규분포
INSTRUCTOR
KEITH  15 MINUTES
분포함수 – 정규분포, Log정규분포


정규분포

우리가 알고 있는 가장 일반적인 데이터의 분포
학부 저학년 수준의 통계학은 대체로 데이터가 정규분포라는 가정 아래 구성되어 있음
ex1. t-분포는 모수(Population)가 정규분포일 때 샘플 추출을 했다는 가정에서 나온 분포함수
ex2. 모수(Population)가 정규분포가 아니라면 반드시 샘플이 t-분포를 따른다고 할 수 없음
 

*용어설명

모수(Population) – 전체 데이터 (ex. 한국 전체 투표 인구)
표본(Sample) – 모수의 일부분 데이터 (ex. 여론조사에 쓰는 1,004명의 표본)
 

*중심극한정리(Central Limit Theorem)

샘플을 뽑아 평균을 계산하고, 다시 또 샘플을 뽑아 평균을 계산하고…… 와 같은 작업을 수백번했을 때, 샘플들의 평균값이 모수(Population)의 평균값 근처에서 정규분포를 따른다는 가정 & 수학적인 증명

 

*중심극한정리를 잘못 활용하는 사례

어떤 데이터건 샘플은 무조건 정규분포를 따른다
데이터가 많으면 정규분포다
모수(Population)의 분포와 상관없이 통계 테스트는 무조건 t-test를 쓰면 된다. 왜? 어차피 정규분포니까
 

정규분포가 아닌 분포함수의 사례

Log 정규분포 – ex. 주식가격,
Why? 주가 수익률이 정규분포라면, 주식 가격은 Log 정규분포를 따르게 된다. 강의노트 수식 증명 참고)
Poisson 분포 – ex. 온라인 광고 클릭 고객 숫자, 쇼핑몰에서 구매 고객 숫자 등
 

Q. 모수(Population)가 정규분포가 아닌데 t-test를 이용해서 테스트하면 잘못인가?

A. 강의 후반의 Type I, II error 부분 참조

 

Q. 주가 수익률이 정규분포를 따르지 않는다면?

A. 일시적으로 상승/하락 경향성 (Momentum)이 있어서 일별 주가 수익률이 정규분포와 약간 어긋날 수 있으나, 장기적으로는 정규 분포에 수렴하는 경향성을 보임. 데이터 사이언스 기본강좌 초반부에 실제 데이터로 증명


Central Limit Theorem에 의해 정규분포 형태.  
Sample들의 평균.

그러나 상당수의 데이터는 정규분포가 아닌 경우가 많다.  

주가는 Log정규분포(음수가 불가능),  
주가 수익률은 정규분포를 따른다.  

log(y/y) = y/y 는 매우 작은 값에서 근사  
정규분포의 합과 차는 정규분포를 따른다.  
Log 정규분포는 Log한 값이 정규분포를 따르는 것.  

주가 수익률이 정규분포를 따르기 때문에 특정한 모멘텀이나 조건을 찾는 것이 아니면 주가 수익률을 예측하는 것은 쉽지 않다.  

## 이항분포와 Poisson 분포
n 커지면 CLT때문에 정규분포로 수렴.  

이항분포

2가지 가능성만 있는 경우에 확률이 반반 (or 1/2 과 유사)인 사건을 여러번 모으면 나타나는 분포함수
중심극한정리 (Central Limit Theorem)에 따라 샘플의 평균(n x p)이 모수의 평균과 비슷한 값이 나오고, 그 값들을 모으면 정규분포와 비슷한 모양이므로, 이항분포의 샘플 평균들의 집합은 정규분포를 따르게 된다
이항분포가 정규분포를 따르는 것이 아니라, 이항분포 샘플들의 평균을 수백, 수천개 모았을 때 정규분포와 비슷한 모양이라는 뜻!
 

Poisson 분포

만약 확률이 반반이 아니라면? 한쪽으로 확 쏠린 경우라면?
ex. 사람이 자동차에 치일 확률, 온라인 광고에 클릭하는 확률, 쇼핑몰에서 상품을 구매하는 확률 등등
이항분포에서 확률값만 0에 수렴하게 바꾸면 강의노트의 Poisson 분포함수로 변형시킬 수 있음
일반적으로 Right-skewed (왼쪽으로 쏠려있고, 오른쪽으로 꼬리가 굉장히 길게 나 있는) 분포함수
 

내 데이터와 분포함수가 얼마나 일치하는지를 찾아내는 방법

아이디어: 데이터의 Histogram이 실제 분포함수와 얼마나 닮아있는지를 확인해서 싱크로율이 높을 수록 일치한다고 판단
포아송 분포의 경우 사건이 0번, 1번, 2번,…. 일어날 가능성에 대한 관찰 결과 (데이터)와 기대값 (분포함수에서 계산한 값)을 비교해본다
정규분포의 경우 Quantile-Quantile (Q-Q) plot을 그려 n% quantile에 있는 값이 실제 정규분포의 n% quantile이 배치된 순서와 같은지 확인
정규분포는 가운데가 볼록한 종모양의 분포함수를 가지므로, 25% ~ 75% Quantile에 모인 값들은 밀집도가 높은 반면, 그 외에 있는 데이터의 밀집도가 낮기 때문에 데이터와 분포함수간 Quantile을 비교하면 유사성을 쉽게 확인할 수 있다.
 

*프랑스 수학자 Poisson이 분포함수를 찾아낸 계기

나폴레옹이 1815년에 엘바섬에서 탈출해 워털루 전쟁을 치르기 직전, 기병과 보병의 배열을 가까이 붙였을 때 말의 뒷발에 맞아 죽는 병사가 생기는 것을 우려한 나폴레옹이 이동 중 병사 손실이 얼마나 될까를 계산해달라고 부탁한데서 출발. 이항분포와 유사한 상황이지만, 확률이 매우 낮은 경우에 어떤 분포가 나올지 계산하는데서 찾아낸 분포함수.

워털루에서 패배한 나폴레옹은 결국 대서양 한가운데에 있는 세인트헬레나 섬에 유배당해 거기서 운명한다.

이항 -> 정규분포 p ~~ 0.5    
이항 -> 포아송  p값 매우 낮을 때, n 클 때

차이값이 많을수록 -> 랜덤이 아니다  
차이값이 없을수록 -> 랜덤이다  



###이 수업에서 가장 중요한 증명

최우추정법(Maximum Likelihood Estimation, MLE)

Likelihood의 다른 표현은 “확률”
**분포함수를 알고 있을 때**, 그 분포함수에서 가장 확률적으로 자주 일어날 것 같은 사건을 찾아내는 계산
MLE로 찾아낸 통계량 (ex. 평균, 분산…)은 데이터가 많을 때, 가장 오차가 작은 계산, 즉 Best Unbiased Estimator (BUE)라고 부름
머신러닝에서는 Expectation Maximization (EM)에서 활용

MLE와 Linear Model간의 관계

제곱근의 오차를 최소화하는 회귀분석 계산과 정규분포의 MLE 계산간 결과값이 일치(Normal Equation이랑 같다, 정규분포에서 나와서 Normal인 것)
일반적으로 제곱근의 오차를 최소화하는 공식을 Best Linear Unbiased Estimator (BLUE)라고 부름
데이터 분포가 정규분포를 따른다면, Linear 모델 중 Best 모델이 Linear가 아닌 모델 중에서도 최고라는 뜻
데이터가 정규분포를 따른다면 기존의 통계학에서 활용하던 제곱근 오차 최소화가 복잡한 Non-linear 모델들 (ex. 머신러닝)보다 더 우월하다는 뜻
데이터가 정규분포를 따른다는 것은 이항분포의 확률 반반 같은 Random data인 경우
**결론: 데이터가 Random이라면, 머신러닝의 복잡한 모델링보다 기초 통계학의 회귀분석 모델이 더 좋다!**

머신러닝 모델이 최근에와서 갑자기 많이 활용되고 성과를 보이는 이유는 인류가 만나는 데이터가 **더 이상 정규분포형 데이터가 아니기 때문**이다. 바둑 데이터는 꼼꼼한 전략에 바탕을 둔, 패턴을 갖고 있는 데이터, 랜덤이 아닌 데이터이고, 온라인에서 상품  추천해주는 모델도 랜덤하게 아무 상품이나 사는 데이터가 아니라, 구매자가 특정한 패턴을 갖고 정보 습득을 했던 것을 추적한 데이터를 활용하고 있기 때문이다.


앞으로 누가 빅데이터는 대용량 데이터고, 머신러닝은 모든 걸 다 바꿀 수 있다고 하면?

**특정 행동 패턴이 있는 데이터, 랜덤이 아닌 데이터가 빅데이터의 자격이 있고, 머신러닝은 그런 데이터에서 Non-linear 패턴을 찾아내는데서만 효과가 있다고 대답해 줄 것!**


정규분포면 -> 통계학으로 돌아가서 Normal Equation  
정규분포가 아니면 -> G.L.S. 조금 형태만 바꾸면 됨.  

바둑은 전략이 있다.  
전략과 규칙이 있는 Data는 Random이 아니다.  
그러면 ML이 적용 가능한 것이다!

# Hypothesis Testing
## Sampling
모집단에서 이를 잘 대표하는 샘플을 추출하기 위해서 고려해야할 사항들이 있다.  

다른 조건에서 뽑았을수도.. Control effect 고려  

ATE -> Control Effect 빼주는것

## t-Test, A/B Test
t-test vs. A/B test

t-test는 테스트하는 변수가 1개인 경우 (샘플의 평균만 계산, Population의 평균은 계산 하지 X)
A/B test는 테스트하는 변수가 2개인 경우 (Control 그룹과 Variant 그룹의 평균을 비교)
 

A/B test시 주의사항

데이터가 많을수록 표준오차 (t-stat의 분모)가 작아지므로 t-stat의 정확도 증가
But!!! N1과 N2가 골고루 증가할수록 유리, 한쪽만 증가할 경우 통계량(test stat)을 부정확하게 만들 가능성 증가
앞 장에서 본 Time effect를 고려, 장기간 데이터를 활용하는 것은 테스트의 정확도를 낮출 수 있음
 

t-Test는 변수 하나에 대해 정규분포에서 구간 내에 있는지 찾는것.

A/B test는 데이터 그룹 두개에 대해서.  
분모는 공분산  

만약 A/B 테스트 할 때 50/50이 아니라 90/10 으로 쪼개면 어떻게 될까?  

bias한 결과가 나옴. 그래서 양쪽다 충분한 샘플 수를 확보하여야 한다.

## Type I, II errors
Type I error: 맞는걸 틀렸다고 할 때 (암에 걸렸는데도 불구하고 안 걸렸다는 진단이 나왔을 때)  
실제론 H0에 해당하는 것인데 샘플링 잘못해서 H0이 아니라고 생각되는 $$\alpha$$가 결과로 나왔을 때. 그럼 H0가 틀렸다고 생각할 것임.

Type II error: 틀린걸 맞다고 할 때 (암에 안 걸렸는데도 불구하고 암에 걸렸다는 진단이 나왔을 때)  
실제론 H1인데 H0으로 판단될 때.  

$$\alpha$$ 늘리면 Type I 에러 늘어남.  
$$\beta$$ 늘리면 Type II 에러 늘어남.

일반적으로 이럴 땐 Type I 에러를 5%에 고정하고,  
Type II 에러를 얼마나 줄일 수 있을까를 고민해본다. 

1-$$\beta$$ 가 1에 가까울 수록 Test power(검정력)이 좋다고 한다.  
이를 위해선 데이터 갯수를 늘리면 됨. 대수의 법칙에 의해 표준오차가 줄어듬. $$\frac{S,\sqrt{N}}$$  
그러나 모델이 틀리면 N을 증가시켜도 오차가 안줄어듬.  

Skewed class (또는 Imbalanced data)인 경우 (ex. Poisson distribution)

정규분포 기반의 t-test는 좌우 대칭형 분포를 가정하고 있기 때문에 p-value 값이 틀릴 수 밖에 없음  
A/B Test에 활용되는 t-stat 계산 방식도 당연히 바뀌어야. t-Test 하지 마라!    
[관련 Wikipedia 링크](https://en.wikipedia.org/wiki/A/B_testing)
 

분포함수 차이에 따른 통계 테스트 방법 차이 간단 예시  

정규분포: Student’s t-test (일반적으로 알려진 t-test)  
이항분포: Fisher’s exact test (Wikipedia 링크 참조)  
[링크](https://en.wikipedia.org/wiki/Fisher%27s_exact_test)  
포아송분포: E-test 또는 C-test (링크의 논문 참조)  
[링크](https://www.sciencedirect.com/science/article/pii/S0378375802004081?via%3Dihub)  
Multinomial: 카이스퀘어 (Chi-squared) 검정  
[링크](https://en.wikipedia.org/wiki/Chi-squared_test)  
분포를 모를 때: Mann-Whiney U test 또는 Gibbs sampling 활용  
[링크](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)  
[링크](https://en.wikipedia.org/wiki/Gibbs_sampling)


## Skewed Class
![skewed](assets/figures/SkewedClass.png)

Alpha: 노란색 형광펜 부분
TP: 연두색 점선 우측, 하늘색 곡선 아래
FP: 연두색 점선 우측, 하늘색 곡선 위, 검은색 곡선 아래
FN: 연두색 점선 좌측, 하늘색 곡선 아래
TN: 연두색 점선 좌측, 하늘색 곡선 위, 검은색 곡선 아래

Type I, II error는 ML에서는 Recall, Precision으로 표현됨.  

Precision만 높다고 좋은 것이 아니다.

99%가 건강하고, 1%가 암에 걸렸다고 판단을 할 때,
100% 다 건강하다고 판단을 한다면, 이건 아무런 정보도 주지 못한다. 이건 진단킷이 아무런 효과를 주지 않는 것.  

Precision과 Recall 둘다 좋아야한다.  

그래서 Accuracy를 따지거나, F1 score(조화평균) 사용한다.  

$$\frac{P+R,2} >= \sqrt{PR} >= \frac{2PR,P+R}$$

area under the curve(AUC) 도 자주 쓰임.  
[AUC](https://bcho.tistory.com/tag/F1%20score)  

# Variable
## Omitted Variable
도구 변수 (Instrumental variable) 활용 예시: 흡연이 건강에 미치는 영향을 측정할 경우

다른 변수들 (식사, 운동 습관, 유전자 등등) 도 건강상태에 영향을 미칠 수 있음
건강 상태에 대한 스트레스로 흡연을 하게되는 역-인과관계가 생길수도 있음
 

적합한 도구 변수는?

담배에 대한 세율
 

적절한 이유

담배세율이 직접적으로 건강에 영향을 미치지 않음
담배세율이 흡연에 영향을 줘서, 흡연이 담배에 영향을 주도록 함
담배세율에 따라 흡연율이 차이날 가능성 높음
 

적절한 도구 변수의 조건

X를 이용해 Y를 설명하려고 할 때
X를 구할 수 없거나,
부정확하거나,
X와 Y간 상관관계가 있다고 판단될 경우,
X와 상관관계가 매우 높은 외부 변수 and
Y에 직접 영향을 미치지는 않지만, X에게 영향을 줘서 Y에게 영향을 끼치는 변수를 찾을 것

''
원래 Y를 설명하기 위해 Z를 사용하는 것이 좋은데, Z가 없어서 X만 가지고 설명을 하면.  

X와 Z가 겹치지않는 관계라면(서로 영향 X, 교집합 없음, $$x \ortho z$$),  
$$오차항 e = \beta_2 Z + \epsilon2$$  

겹친다면  
$$오차항 e != \beta_2 Z + \epsilon2$$  
$$||b_1|| > ||\beta_1||$$  
$$\beta_2 = \beta_1/2$$  

Saddle Point는 x축방향에선 convex, y축 방향에선 concave하게 보일 수 있다. 어디서는 최소로, 어디서는 최대로 보인다.  
데이터가 부족하면(축이 부족) Saddle Point에 얹혀진 모양이 될 수 있다.  

필요한 데이터를 직접 구하지 못한다면 도구변수를 이용하자.  
span이 같거나, 최소한 비슷한 변수를 활용.  
ex) 키와 발길이

## Measurement Error
[Attenuated bias](https://web.stanford.edu/~doubleh/eco273B/survey-jan27chenhandenis-07.pdf) 

$$\hat{\Beta_1} = Normal Equation으로$$  

베타는 0 근처로 모이게됨. 더 작아지게됨.  

![Attenuated bias](assets/figures/Attenuated bias.png)  

그래서 결과값이 잘 안나오는 경우 모델자체의 문제도 있을 수 있지만, 그보다 입력하는 데이터가 엉망이면 오차가 수정되지 않기 때문에 결과가 나오지않는다. 그래서 입력 데이터를 잘 살펴보아야한다.  

그래서 Measurement Error는 매우 중요한 것이다.  

복잡한 모델일수록 모델이 정말로 깔끔한 데이터를 쓰고있는지 확인해보아야한다.  

## Simultaneity bias
Spurious regression (외부링크, pabii 블로그)  
[외부](https://en.wikipedia.org/wiki/Spurious_relationship)  
[pabii](https://blog.pabii.co/granger-causality/)

두 변수가 실질적으로는 아무런 관계도 갖고 있지 않지만, 통계적으로 매우 높은 상관관계를 보이는 경우
ex1. 여름에 아이스크림 판매량이 증가하는 것과 해변가 상어 출몰 횟수가 동시에 높다는 이유로 아이스크림을 먹으면 상어한테 습격당할 수 있다고 생각하는 것
ex2. 시간의 흐름에 따라 바뀌는 변수들간의 관계 – 전쟁 후 인구 증가, 과학 발달로 인한 수명 연장을 놓고, 인구가 증가하면 수명이 증가한다고 결론 내리는 것
앞에서 배운 도구 변수 (Instrumental variable)을 추가하거나, 블로그 링크에 있는 Granger causality를 이용하는 방법 등이 있지만
기술적으로 완전한 제거 방법을 찾기보다, 합리적으로 실질적인 연관관계가 있는지를 따지는 것을 추천

Correlation이 있다고 해서 둘이 꼭 인과관계가 있는 것은 아니다.  

Correlation != Causality  

Correlation만을 통해서 관계를 설정하면 순환적으로 서로의 변수를 설명하는 Cycle이 생김.  

Spurious Regression -> Correlation - Causality

X축 런던에 비가옴(런던엔 비가 맨날옴)  
Y축 스코틀랜드 정화조(스코틀랜드 정화조 맨날 청소함) 

사회과학에서 R제곱이 0.3 넘으면 높다고 생가각하는데,  
위의 예는 0.99가나옴.  

# One Hot Encoding
## Dummy Variable
코딩용 패키지 명칭들: Dummification, one-hot-encodning, categorical variables…

Y절편을 가져가면, Z1+Z2+Z3+Z4=1 인데, Y절편용 데이터는 늘 1이므로, Linear dependency가 생긴다.  

두가지 방법
1. Y절편을 버린다  
2. 봄, 여름, 가을, 겨울 중 한개의 값만 버린다.  
봄 y=B1(+epsilon)  
여름 y=B2  
가을 y=B3  
겨울 y=B4  

겨울만 날린다고 하면,  
봄 y=B0 + B1  
여름 y=B0 + B2  
가을 y=B0 + B3  
겨울 y=B0 (겨울 값 버렸음, B4=0)  

Samsung, LG, Others
1   0   0  
0   1   0  
0   0   1  

으로 표현하고, dependency처리를 위해서 Others를 강제로 0으로 만든다. Bias를 0으로 만들거나.  