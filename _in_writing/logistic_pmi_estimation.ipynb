{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72523\t명불허전\t1\n",
      "72523\t왠지 고사 피의 중간 고사 보다 재미 가 없을 듯해요 만약 보게 된다 면 실망 할듯\t1\n",
      "72523\t티아라 사랑 해 ㅜ\t10\n"
     ]
    }
   ],
   "source": [
    "tokenized_comments_fname = '/mnt/lovit/works/fastcampus_text_ml/3rd//data/comments_172movies/merged_comments_tokenized.txt'\n",
    "with open(tokenized_comments_fname, encoding='utf-8') as f:\n",
    "    for _ in range(3):\n",
    "        print(next(f).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_reviews(fname, n_limit=-1):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        idxs = []\n",
    "        scores = []\n",
    "        texts = []\n",
    "        \n",
    "        for i, doc in enumerate(f):\n",
    "            if n_limit > 0 and i >= n_limit:\n",
    "                break\n",
    "                \n",
    "            try:\n",
    "                idx, text, score = doc.strip().split('\\t')\n",
    "                idxs.append(idx)\n",
    "                texts.append(text)\n",
    "                scores.append(int(score))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "                \n",
    "    return idxs, texts, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3280685\n"
     ]
    }
   ],
   "source": [
    "idxs, texts, scores = load_reviews(tokenized_comments_fname)\n",
    "print(len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_counter = Counter([word for text in texts for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('영화', 1412516),\n",
       " ('이', 764006),\n",
       " ('관람객', 585858),\n",
       " ('는', 459876),\n",
       " ('가', 438771),\n",
       " ('도', 418073),\n",
       " ('의', 403943),\n",
       " ('다', 381746),\n",
       " ('재밌', 370724),\n",
       " ('재미', 344634),\n",
       " ('너무', 335529),\n",
       " ('ㅋㅋ', 321284),\n",
       " ('정말', 297962),\n",
       " ('고', 294644),\n",
       " ('을', 270826),\n",
       " ('에', 266720),\n",
       " ('한', 263385),\n",
       " ('를', 263311),\n",
       " ('연기', 255673),\n",
       " ('최고', 254291)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_counter.items(), key=lambda x:x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "341744 --> 49901\n"
     ]
    }
   ],
   "source": [
    "n_before = len(word_counter)\n",
    "\n",
    "min_count = 10\n",
    "word_dictionary = {\n",
    "    word:freq for word,freq in word_counter.items()\n",
    "    if freq >= min_count and len(word) > 1\n",
    "}\n",
    "\n",
    "n_after  = len(word_dictionary)\n",
    "\n",
    "print('%d --> %d' % (n_before, n_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 1: (320898, 9.781 perc)\n",
      "score = 2: (34351, 1.047 perc)\n",
      "score = 3: (35580, 1.085 perc)\n",
      "score = 4: (39742, 1.211 perc)\n",
      "score = 5: (78250, 2.385 perc)\n",
      "score = 6: (95834, 2.921 perc)\n",
      "score = 7: (149618, 4.561 perc)\n",
      "score = 8: (268622, 8.188 perc)\n",
      "score = 9: (344905, 10.513 perc)\n",
      "score = 10: (1912885, 58.307 perc)\n"
     ]
    }
   ],
   "source": [
    "for score, freq in sorted(Counter(scores).items()):\n",
    "    perc = 100 * freq / len(scores)\n",
    "    print('score = %d: (%d, %.3f perc)' % (score, freq, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 3280685 --> 2622411\n",
      "label = 0: (387039, 14.759 perc)\n",
      "label = 1: (2235372, 85.241 perc)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_texts = []\n",
    "train_label = []\n",
    "\n",
    "for text, score in zip(texts, scores):\n",
    "\n",
    "    # skip 4 ~ 8 scored reviews\n",
    "    if 4 <= score <= 8:\n",
    "        continue\n",
    "\n",
    "    # skip empty reviews\n",
    "    words = [word for word in text.split() if word in word_dictionary]\n",
    "    if not words:\n",
    "        continue\n",
    "\n",
    "    # append text and label\n",
    "    train_texts.append(words)\n",
    "    train_label.append(1 if score > 8 else 0)\n",
    "\n",
    "train_label = np.asarray(train_label)\n",
    "\n",
    "print('train data: %d --> %d' % (len(texts), len(train_texts)))\n",
    "\n",
    "for label, freq in Counter(train_label).items():\n",
    "    perc = 100 * freq / len(train_label)\n",
    "    print('label = %d: (%d, %.3f perc)' % (label, freq, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2622411, 49896)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=lambda x:x, lowercase=False)\n",
    "train_x = vectorizer.fit_transform(train_texts)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('./tmp/sentiment_vocablist', 'w', encoding='utf-8') as f:\n",
    "#     for word, _ in sorted(vectorizer.vocabulary_.items(), key=lambda x:x[1]):\n",
    "#         f.write('%s\\n' % word)\n",
    "vocablist = [\n",
    "    word for word, _ in sorted(\n",
    "        vectorizer.vocabulary_.items(), key=lambda x:x[1]\n",
    "    )\n",
    "]\n",
    "\n",
    "vocabcount = [word_dictionary[word] for word in vocablist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "logistic_l2 = LogisticRegression(verbose=True)\n",
    "logistic_l2.fit(train_x, train_label)\n",
    "predict_label_l2 = logistic_l2.predict(train_x)\n",
    "\n",
    "logistic_l1 = LogisticRegression(verbose=True, penalty='l1')\n",
    "logistic_l1.fit(train_x, train_label)\n",
    "predict_label_l1 = logistic_l2.predict(train_x)\n",
    "\n",
    "bayes = BernoulliNB()\n",
    "bayes.fit(train_x, train_label)\n",
    "predict_label_nb = bayes.predict(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = train_x\n",
    "y = train_label\n",
    "\n",
    "\n",
    "unique = np.unique(y)\n",
    "print(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 = 0.9331332884128384\n",
      "l1 = 0.9331332884128384\n",
      "NB = 0.9031345582366761\n",
      "pmi (t=-1.754) = 0.9067373497136795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/ipykernel_launcher.py:21: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[1]\n",
    "n_classes = unique.shape[0]\n",
    "coefs = np.zeros((n_classes, n_features))\n",
    "\n",
    "Py = np.asarray(X.sum(axis=0)).reshape(-1)\n",
    "Py = Py / Py.sum()\n",
    "Px = np.zeros(n_classes)\n",
    "Pxy = np.zeros((n_classes, n_features))\n",
    "Py_x = np.zeros((n_classes, n_features))\n",
    "\n",
    "for c, label in enumerate(unique):\n",
    "    indices = np.where(y == label)[0]\n",
    "    Py_x_ = np.asarray(X[indices].sum(axis=0)).reshape(-1)\n",
    "    Py_x_ = Py_x_ / Py_x_.sum()\n",
    "    Pxy[c] = (Py_x_ / Py)\n",
    "    Py_x[c] = Py_x_\n",
    "    Px[c] = indices.shape[0]\n",
    "Px = Px / Px.sum()\n",
    "Px = np.log(Px)\n",
    "\n",
    "PMIxy = np.log(Pxy)\n",
    "PMIxy = np.nan_to_num(PMIxy)\n",
    "PMIxy[np.where(PMIxy < -5)] = 0\n",
    "coefs = (PMIxy[1] - PMIxy[0])\n",
    "t = -(Px[1] - Px[0])\n",
    "\n",
    "keyword_score = Py_x[1] - Py_x[0]\n",
    "\n",
    "def predict(X, coefs, t=0):\n",
    "    y = X.dot(coefs)\n",
    "    y[np.where(y >= t)[0]]= 1\n",
    "    y[np.where(y < t)[0]] = 0\n",
    "    return y\n",
    "\n",
    "def accuracy(answer, prediction):\n",
    "    return (answer == prediction).sum() / answer.shape[0]\n",
    "\n",
    "predict_label = predict(X, coefs, t)\n",
    "print('l2 = {}'.format(accuracy(train_label, predict_label_l2)))\n",
    "print('l1 = {}'.format(accuracy(train_label, predict_label_l1)))\n",
    "print('NB = {}'.format(accuracy(train_label, predict_label_nb)))\n",
    "print('pmi (t={:.3f}) = {}'.format(t, accuracy(train_label, predict_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lovit/anaconda2/envs/scrapper/lib/python3.6/site-packages/ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 = 0.9331332884128384\n",
      "l1 = 0.9331332884128384\n",
      "NB = 0.9031345582366761\n",
      "pmi (t=-1.754) = 0.9067373497136795\n"
     ]
    }
   ],
   "source": [
    "# softmax version\n",
    "\n",
    "n_features = X.shape[1]\n",
    "n_classes = unique.shape[0]\n",
    "coefs = np.zeros((n_classes, n_features))\n",
    "\n",
    "Py = np.asarray(X.sum(axis=0)).reshape(-1)\n",
    "Py = Py / Py.sum()\n",
    "Px = np.zeros(n_classes)\n",
    "Pxy = np.zeros((n_classes, n_features))\n",
    "Py_x = np.zeros((n_classes, n_features))\n",
    "\n",
    "for c, label in enumerate(unique):\n",
    "    indices = np.where(y == label)[0]\n",
    "    Py_x_ = np.asarray(X[indices].sum(axis=0)).reshape(-1)\n",
    "    Py_x_ = Py_x_ / Py_x_.sum()\n",
    "    Pxy[c] = (Py_x_ / Py)\n",
    "    Py_x[c] = Py_x_\n",
    "    Px[c] = indices.shape[0]\n",
    "Px = Px / Px.sum()\n",
    "Px = np.log(Px)\n",
    "\n",
    "PMIxy = np.log(Pxy)\n",
    "PMIxy = np.nan_to_num(PMIxy)\n",
    "PMIxy[np.where(PMIxy < -5)] = 0\n",
    "coefs = PMIxy.copy().T\n",
    "beta = Px\n",
    "\n",
    "def softmax(X, coefs, beta):\n",
    "    prod = X.dot(coefs)\n",
    "    prod += beta\n",
    "    y = prod.argmax(axis=1)\n",
    "    return y\n",
    "\n",
    "def softmax_prob(X, coefs, beta):\n",
    "    prod = X.dot(coefs)\n",
    "    prod += beta\n",
    "    prob = np.exp(prod)\n",
    "    prob /= prob.sum(axis=1)[:,np.newaxis]\n",
    "    return prob\n",
    "\n",
    "def accuracy(answer, prediction):\n",
    "    return (answer == prediction).sum() / answer.shape[0]\n",
    "\n",
    "predict_label = softmax(X, coefs, beta)\n",
    "print('l2 = {}'.format(accuracy(train_label, predict_label_l2)))\n",
    "print('l1 = {}'.format(accuracy(train_label, predict_label_l1)))\n",
    "print('NB = {}'.format(accuracy(train_label, predict_label_nb)))\n",
    "print('pmi (t={:.3f}) = {}'.format(t, accuracy(train_label, predict_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.91332394, -0.15968647])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## positive term ##\n",
      "| 관람객 | 재밌 | 최고 | 습니다 | 정말 | 감동 | 연기 | ㅠㅠ | 대박 | 어요 |\n",
      "| 보고 | ㅎㅎ | 입니다 | 진짜 | 재밋 | 완전 | 합니다 | 기대 | 었어요 | 좋았 |\n",
      "| 네요 | 강추 | 있었 | 눈물 | 봤어요 | 너무 | 생각 | 있는 | 적이 | 봐야 |\n",
      "| 다시 | 역시 | 있게 | 재미 | 추천 | 가슴 | 있고 | 한번 | 필요 | ㅋㅋ |\n",
      "| 사랑 | 마지막 | 영화 | 잼있 | 우리 | 오랜만에 | 감사 | 있어 | 멋있 | 봐도 |\n",
      "| 마음 | 울었 | 꿀잼 | 좋아 | 액션 | 긴장 | 같아요 | 말이 | 에요 | 였습니다 |\n",
      "| ㅜㅜ | 적인 | 스릴 | 봤는데 | 여운이 | 괜찮 | 슬프 | 좋고 | 몰입 | 좋은 |\n",
      "| 분들 | 보세요 | 모두 | 소름 | 하게 | 간만에 | 후회 | 짱짱 | 봤네요 | 명작 |\n",
      "| 잘봤 | 굿굿 | 였어요 | 하정우 | 함께 | 두번 | 었음 | 들의 | 따뜻 | 까지 |\n",
      "| 아깝지 | 가족 | 인생 | 멋진 | 잘하 | 만큼 | 엄청 | 시간가는줄 | 매력 | 조금 |\n",
      "| 탄탄 | 볼만 | 안하고 | 만점 | 약간 | 올해 | 계속 | 음악 | 펑펑 | 지금 |\n",
      "| 꼭보세요 | 반전 | 아주 | 웃고 | 재밋어요 | 유아인 | 오늘 | 모든 | 보게 | 해요 |\n",
      "| 있다 | 가장 | 하지만 | 싶다 | 울고 | 흥미 | 없이 | 또보고싶 | 작품 | 였다 |\n",
      "| 멋지 | 짱이 | 빨리 | 있네요 | 모습 | 먹먹 | 많은 | 즐거 | 않았 | 행복 |\n",
      "| 훌륭 | 황정민 | 마블 | 지만 | 화이팅 | 대단 | 쵝오 | 특히 | 있음 | 었다 |\n",
      "| 빠져 | 완벽 | 그리고 | 눈을 | 충분 | 표현 | 만족 | 아쉬 | 않은 | 잔잔 |\n",
      "| 원빈 | 예요 | 아버지 | 아름다운 | 됩니 | 웃다가 | 잊지 | 신선 | 볼수 | go |\n",
      "| 싶은 | 있어서 | 코믹 | 나름 | 여운 | 슬픈 | 부모님 | 봤음 | 놀란 | 했지만 |\n",
      "| 중에 | 싶어요 | 그래도 | 노래 | 웃음 | 많이 | 안보면 | 내내 | 믿고 | 나라 |\n",
      "| 잼나 | 않고 | 싶네요 | 살아 | 순간 | 진진 | 시리즈 | 좋다 | 감탄 | 꼭보 |\n"
     ]
    }
   ],
   "source": [
    "words = [vocablist[idx] for idx in keyword_score.argsort()[::-1][:200]]\n",
    "print('## positive term ##')\n",
    "for i in range(20):\n",
    "    print('| {} |'.format(' | '.join(words[i*10:(i+1)*10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## negative term ##\n",
      "| 평점 | 알바 | 쓰레기 | 1점 | 없고 | 지루 | 별로 | ㅡㅡ | 스토리 | 아니 |\n",
      "| 실망 | 하고 | 아깝다 | 억지 | 없는 | 없다 | 그냥 | 내용 | 이게 | 선동 |\n",
      "| 최악 | 감독 | 없음 | 이런 | 이건 | OO | 최악의 | 수준 | 아까 | 솔직 |\n",
      "| 유치 | 만들 | 라고 | 짜증 | 노잼 | 없어 | 아까운 | 0점 | 으로 | 무슨 |\n",
      "| 이거 | 개연성 | 돈아까 | 하는 | 정도 | 차라리 | 시간 | 보다가 | 것도 | 하나 |\n",
      "| 뻔한 | 사람 | 아깝 | ㅉㅉ | 나오 | 같은 | 려고 | 때문에 | 건지 | 하다 |\n",
      "| 해서 | 전개 | 광주 | 렇게 | 효주 | 떨어 | 아닌 | 겠다 | 돈아깝 | 이딴 |\n",
      "| 중간 | 했다 | 점수 | 절대 | 이걸 | 관객 | 안되 | 돈주고 | 인지 | 폭동 |\n",
      "| 7점 | 드라마 | 도대체 | 졸작 | 네이버 | 거지 | 보지마 | 높아 | 왜곡 | 보지마세요 |\n",
      "| 설정 | 만든 | 그만 | 폭동이 | CG | 비추 | 적당 | 높은 | 장난 | 준다 |\n",
      "| 놓고 | 그나마 | 엉성 | 내가 | 없네 | 인가 | 제발 | 들은 | 이하 | 제작 |\n",
      "| 없어서 | 돈이 | 연출 | 어이 | 시나리오 | 건가 | 별루 | 미화 | 느낌 | 캐스팅 |\n",
      "| 여자 | 지도 | 그닥 | 초딩 | 짜리 | 잖아 | 북한 | 뻔하 | 2점 | 주인공 |\n",
      "| 낭비 | 내돈 | 아님 | 18 | 허접 | 못하 | 6점 | 하기 | 라도 | 8점 |\n",
      "| 감성팔이 | 디워 | 답답 | 광고 | 보지 | 그래 | ㅅㅂ | 높다 | 아무리 | 3류 |\n",
      "| cg | 밖에 | 5점 | 미국 | 3점 | 일본 | O기 | 마라 | 어이없 | 예고편 |\n",
      "| 엉망 | 신파 | 댓글 | 이나 | 없었 | 조작 | 알았 | 들이 | 막장 | 주고 |\n",
      "| 애들 | 그저 | 삼류 | 뭐가 | 망작 | 진심 | 뭐냐 | 존나 | 허무 | 뭐야 |\n",
      "| 왜이 | 인데 | 떻게 | 전혀 | 별점 | 받아 | 홍보 | 기분 | 하네 | 심하 |\n",
      "| 졸았 | 괴물 | 에휴 | 만드 | 말도 | 대체 | 그렇 | 따라 | 전부 | 이해 |\n"
     ]
    }
   ],
   "source": [
    "words = [vocablist[idx] for idx in keyword_score.argsort()[:200]]\n",
    "print('## negative term ##')\n",
    "for i in range(20):\n",
    "    print('| {} |'.format(' | '.join(words[i*10:(i+1)*10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
